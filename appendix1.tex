\chapter{Proofs for Chapter 2}\label{c2:appendix}

\section{Proof of Theorem \ref{thm:conv}}

We prove the four statements of Theorem \ref{thm:conv} one by one.

\subsection{Proof of Statement \ref{SQMP:1}}

\begin{proof}
Note that we always search solutions in the feasible region
$\mathcal{M}\times \mathcal{X}$ in Algorithm SQMP. Therefore,
Statement \ref{SQMP:1} holds.
\end{proof}


\subsection{Proof of Statement \ref{SQMP:2}}

\begin{proof}
Following the analysis in Section \ref{Section3:2}, in Algorithm
SQMP, we actually solve the following problem in {\bf Step 1}:

{\small{
\begin{equation}\label{Proof:thm3:1}
\max_{\mu\in \mathcal{M}}\quad g^k(\mu,X_{k-1}):={1\over
n}\sum_{j=1}^n \frac{1}{2}a_j
t_j^{k-1}\left[-\left(\xi_j-\mu\right)^T
X_{k-1}\left(\xi_j-\mu\right)+\log\det X_{k-1}\right]+{1\over
n}\sum_{j=1}^na_jt_j^{k-1}\left[1-\log t_j^{k-1}\right],
\end{equation}}}and the following problem in {\bf Step 2}:
\begin{equation}\label{Proof:thm3:2}
\max_{X\in\mathcal {X}}\quad f^k(\mu_{k},X):={1\over n}\sum_{j=1}^n
\frac{1}{2}a_j s_j^k\left[-\left(\xi_j-\mu_{k}\right)^T
X\left(\xi_j-\mu_{k}\right)+\log\det X\right]+{1\over
n}\sum_{j=1}^na_js_j^k\left[1-\log s_j^k\right],
\end{equation}
and $\mu_k$ and $X_k$ are the optimal solutions of Problems
(\ref{Proof:thm3:1}) and (\ref{Proof:thm3:2}), respectively. Since
\begin{eqnarray*}
\lefteqn{\bar g_n(\mu,X_{k-1})-g^k(\mu,X_{k-1})}\\
&=& {1\over n}\sum_{j=1}^n a_jt_j^{k-1}\left\{ \exp\left[-{1\over
2}(\xi_j-\mu)^T X_{k-1}(\xi_j-\mu)+{1\over 2}\log\det X_{k-1}-\log
t_j^{k-1}\right]\right.\nonumber\\
&& \left.-\left[-{1\over 2}(\xi_j-\mu)^T X_{k-1}(\xi_j-\mu)+{1\over
2}\log\det X_{k-1}\right]-\left[1-\log t_j^{k-1}\right]\right\}\\
&\ge& {1\over n}\sum_{j=1}^n a_jt_j^{k-1}\left\{1+\left[-{1\over
2}(\xi_j-\mu)^T X_{k-1}(\xi_j-\mu)+{1\over 2}\log\det X_{k-1}-\log
t_j^{k-1}\right]\right.\nonumber\\
&& \left.-\left[-{1\over 2}(\xi_j-\mu)^T X_{k-1}(\xi_j-\mu)+{1\over
2}\log\det X_{k-1}\right]-\left[1-\log t_j^{k-1}\right]\right\}\\
&=& 0,
\end{eqnarray*}
we obtain that $\bar g_n(\mu,X_{k-1})\ge g^k(\mu,X_{k-1})$ for all
$\mu\in \mathcal {M}$. Moreover, at point $\mu_{k-1}$, we have \[
g^k(\mu_{k-1},X_{k-1})=\frac{1}{n}\sum_{j=1}^na_jt_j^{k-1}=\bar
g_n(\mu_{k-1},X_{k-1}).\]
% and
%\begin{equation*}
%\nabla_{\mu}
%g^k(\mu_{k-1},X_{k-1})=\frac{1}{n}\sum_{j=1}^n\left\{a_jt_j^{k-1}
%\left(X_{k-1}(\xi_j-\mu_{k-1})\right)\right\}=\nabla_\mu\bar
%g_n(\mu_{k-1},X_{k-1}).
%\end{equation*}
Similarly, we have $\bar g_n(\mu_k,X)\ge f^k(\mu_k,X)$ for all $X\in
\mathcal {X}$, and at the point $X_{k-1}$,
\[f^k(\mu_{k},X_{k-1})=\frac{1}{n}\sum_{j=1}^na_js_j^{k}=\bar
g_n(\mu_k,X_{k-1}).\]
%and
%\begin{equation*}
%\nabla_{X}
%f^k(\mu_k,X_{k-1})=\frac{1}{n}\sum_{j=1}^n\left\{\frac{1}{2}a_jt_j^{k-1}
%\left(-(\xi_j-\mu_k)(\xi_j-\mu_k)^T+X_{k-1}^{-1}\right)\right\}=\nabla_X
%\bar g_n(\mu_k,X_{k-1}).
%\end{equation*}

By the above analysis, we have
\begin{eqnarray}\label{Proof:thm3:3}
\bar g_n(\mu_{k+1},X_{k+1}) &\ge& f^{k+1}(\mu_{k+1},X_{k+1})\ \ge\
f^{k+1}(\mu_{k+1},X_{k})\ =\ \bar g_n(\mu_{k+1},X_{k})\nonumber\\
&\ge& g^{k+1}(\mu_{k+1},X_{k})\ \ge\ g^{k+1}(\mu_{k},X_{k})\ =\ \bar
g_n(\mu_{k},X_{k}).
\end{eqnarray}
This shows that the sequence $\left\{\bar
g_n(\mu_k,X_k),k=0,1,\cdots\right\}$ is nondecreasing. Since $\bar
g_n(\cdot)$ is continuous on $\mathcal{M}\times\mathcal{X}$ and
$\mathcal{M}\times\mathcal{X}$ is compact, we have that $\bar
g_n(\cdot)$ is bounded above on $\mathcal{M}\times\mathcal{X}$.
Then, $\left\{\bar g_n(\mu_k,X_k),k=0,1,\cdots\right\}$ converges.
Therefore, Statement \ref{SQMP:2} holds.
\end{proof}


\subsection{Proof of Statement \ref{SQMP:3}}

\begin{proof}
If $(\mu_{k+1},X_{k+1})\not=(\mu_k,X_k)$, then either
$\mu_{k+1}\not=\mu_k$ or $X_{k+1}\not=X_k$. By the strict concavity
of $g^{k+1}(\cdot,X_k)$ and $f^{k+1}(\mu_{k+1},\cdot)$, we have
$g^{k+1}(\mu_{k+1},X_{k})$ is strictly larger than
$g^{k+1}(\mu_k,X_k)$, or $f^{k+1}(\mu_{k+1},X_{k+1})$ is strictly
larger than $f^{k+1}(\mu_{k+1},X_k)$. Then it follows from Equation
(\ref{Proof:thm3:3}) that $\bar g_n(\mu_{k+1},X_{k+1})>\bar
g_n(\mu_k,X_k)$.

For the second assertion, we prove it by contradiction. Suppose
$(\mu_{k+1},X_{k+1})=(\mu_k,X_k)$ and $(\mu_k,X_k)$ is not a
stationary point of Problem (\ref{eqn:saa}). Then, we have either
$\nabla_{\mu} \bar g_n(\mu_k,X_k)\not\in N_{\mathcal{M}}(\mu_k)$ or
$\nabla_{X} \bar g_n(\mu_k,X_k)\not\in N_{\mathcal{X}}(X_k)$. If
$\nabla_{\mu} \bar g_n(\mu_k,X_k)\not\in N_{\mathcal{M}}(\mu_k)$,
then there exists a feasible direction $h$ at $\mu_k$, such that
$\nabla_\mu \bar g_n(\mu_k,X_k)^Th>0$. Since $\nabla_\mu
g^{k+1}(\mu_k,X_k)=\nabla_\mu \bar g_n(\mu_k,X_k)$, we have
$\nabla_\mu g^{k+1}(\mu_k,X_k)^Th>0$. This means there exists some
constant $t_0>0$ such that $\mu_k+t_0h\in \mathcal{M}$ and
\[g^{k+1}(\mu_k+t_0h,X_k)>
g^{k+1}(\mu_k,X_k)=g^{k+1}(\mu_{k+1},X_k).\] This contradicts to the
fact that $\mu_{k+1}$ is the optimal solution.

Similarly, if $\nabla_{X} \bar g_n(\mu_{k+1},X_k)=\nabla_{X} \bar
g_n(\mu_k,X_k)\not\in N_{\mathcal{X}}(X_k)$, then there exists a
feasible direction $H$ at $X_k$, such that ${\bf tr}(\nabla_X \bar
g_n(\mu_{k+1},X_k)H)>0$. Since $\nabla_X
f^{k+1}(\mu_{k+1},X_k)=\nabla_X \bar g_n(\mu_{k+1},X_k)$, we have
${\bf tr}(\nabla_X f^{k+1}(\mu_{k+1},X_k)H)>0$. This means there
exists some constant $t_0>0$ such that $X_k+t_0H\in \mathcal{X}$ and
\[f^{k+1}(\mu_{k+1},X_k+t_0H)>
f^{k+1}(\mu_{k+1},X_k)=f^{k+1}(\mu_{k+1},X_{k+1}).\] This
contradicts to the fact that $X_{k+1}$ is the optimal solution.

Therefore, Statement \ref{SQMP:3} holds.
\end{proof}


\subsection{Proof of Statement \ref{SQMP:4}}

To prove Statement 4, we need the following two lemmas.

\begin{lemma}\label{sec:3:prop:2}
Let $\left\{(\mu_k,X_k), k=0,1,\cdots\right\}$ be a sequence of
solutions generated by Algorithm SQMP starting from $(\mu_0,X_0)\in
\mathcal{M}\times \mathcal{X}$. Then, \[\lim_{k\to
\infty}\left(\|\mu_{k+1}-\mu_{k}\|^2+\|X_{k+1}-X_{k}\|^2\right)
^{1/2}=0.\]
\end{lemma}

\begin{proof}
We prove by contradiction. Suppose the conclusion of the lemma does
not hold. Because of the compactness of $\mathcal{M}\times
\mathcal{X}$, there exists a subsequence
$\left\{(\mu_{k_l},X_{k_l})\right\}$ of
$\left\{(\mu_{k},X_{k})\right\}$ such that $(\mu_{k_l},X_{k_l})\to
(\mu_1^*,X_1^*)$, $(\mu_{k_l+1},X_{k_l+1})\to (\mu_2^*,X_2^*)$, and
$(\mu_1^*,X_1^*)\not=(\mu_2^*,X_2^*)$. Since the sequence
$\left\{\bar g_n(\mu_k,X_k)\right\}$ converges and $\bar
g_n(\mu_{k_l},X_{k_l})\le \bar g_n(\mu_{k_l+1},X_{k_l})\le\bar
g_n(\mu_{k_l+1},X_{k_l+1})$, by continuity we have $\bar
g_n(\mu_1^*,X_1^*)=\bar g_n(\mu_2^*,X_1^*)=\bar g_n(\mu_2^*,X_2^*)$.

If $X_1^*\not=X_2^*$. By Algorithm SQMP, we have
\begin{equation}\label{Proof:thm3:4}
f^{k_l+1}(\mu_{k_l+1},X_{k_l+1})\ge f^{k_l+1}(\mu_{k_l+1},X_1^*).
\end{equation}
Let $s_j^*=
\exp\left\{-\frac{1}{2}(\xi_j-\mu_2^*)^TX_1^*(\xi_j-\mu_2^*)+
\frac{1}{2}\log\det X_1^*\right\}, j=1,\cdots,n$. We define a new
concave conservative function $f^*(\mu_2^*,\cdot)$ of $\bar
g_n(\mu_2^*,\cdot)$ on $\mathcal{X}$:
\begin{equation*}
f^*(\mu_2^*,X)=\frac{1}{n}\sum_{j=1}^n
\left\{a_js_j^*\left[-\frac{1}{2}(\xi_j-\mu_2^*)^TX(\xi_j-\mu_2^*)
+\frac{1}{2}\log\det X\right]+a_j\left(s_j^*-s_j^*\log
s_j^*\right)\right\}.
\end{equation*}
Letting $l\to \infty$ on both sides of (\ref{Proof:thm3:4}) and by
continuity, we have $f^*(\mu_2^*,X_2^*)\ge f^*(\mu_2^*,X_1^*)$. On
the other hand, since $f^*(\mu_2^*,X_2^*)\le \bar
g_n(\mu_2^*,X_2^*)$ and $f^*(\mu_2^*,X_1^*)=\bar
g_n(\mu_2^*,X_1^*)$, we have \[f^*(\mu_2^*,X_2^*)-
f^*(\mu_2^*,X_1^*)\le \bar g_n(\mu_2^*,X_2^*)-\bar
g_n(\mu_2^*,X_1^*)=0.\] Therefore, we obtain that
$f^*(\mu_2^*,X_2^*)=f^*(\mu_2^*,X_1^*)$. Noting that
$X_1^*\not=X_2^*$ and $f^*(\mu_2^*,\cdot)$ is strictly concave on
$\mathcal{X}$, we can find $\varepsilon>0$ such that
\begin{equation}\label{Proof:thm3:5}
f^*\left(\mu_2^*,\frac{X_1^*+X_2^*}{2}\right)\ge
f^*\left(\mu_2^*,X_2^*\right)+\varepsilon.
\end{equation}
Since $(\mu_{k_l},X_{k_l})\to (\mu_1^*,X_1^*)$ and
$(\mu_{k_l+1},X_{k_l+1})\to (\mu_2^*,X_2^*)$, by using the
continuity we have $f^{k_l+1}(\mu_{k_l+1},\frac{X_1^*+X_2^*}{2})\to
f^*(\mu_2^*,\frac{X_1^*+X_2^*}{2})$ and
$f^{k_l+1}(\mu_{k_l+1},X_{k_l+1})\to f^*(\mu_2^*,X_2^*)$, as $l \to
\infty$. Then by (\ref{Proof:thm3:5}), there exists $l_0$, such that
\begin{equation*}
f^{k_{l_0}+1}\left(\mu_{k_{l_0}+1},\frac{X_1^*+X_2^*}{2}\right)\ge
f^{k_{l_0}+1}\left(\mu_{k_{l_0}+1},X_{k_{l_0}+1}\right)+
\frac{\varepsilon}{2}.
\end{equation*}
The above inequality indicates $X_{k_{l_0}+1}$ is not the optimal
solution of Problem (\ref{Proof:thm3:2}) (when $k=k_{l_0}+1$). This
is a contradiction!

Now suppose $X_1^*=X_2^*$, but $\mu_1^*\not=\mu_2^*$. By Algorithm
SQMP, we have
\begin{equation}\label{Proof:thm3:6}
g^{k_l+1}(\mu_{k_l+1},X_{k_l})\ge g^{k_l+1}(\mu_1^*,X_{k_l}).
\end{equation}
Let $t_j^*=
\exp\left\{-\frac{1}{2}(\xi_j-\mu_1^*)^TX_1^*(\xi_j-\mu_1^*)+
\frac{1}{2}\log\det X_1^*\right\}, j=1,\cdots,n$. We define a new
concave conservative function $g^*(\cdot,X_1^*)$ of $\bar
g_n(\cdot,X_1^*)$ on $\mathcal{M}$:
\begin{equation*}
g^*(\mu,X_1^*)=\frac{1}{n}\sum_{j=1}^n
\left\{a_jt_j^*\left(-\frac{1}{2}(\xi_j-\mu)^TX_1^*(\xi_j-\mu)
+\frac{1}{2}\log\det X_1^*\right)+a_j\left(t_j^*-t_j^*\log
t_j^*\right)\right\}.
\end{equation*}
Letting $l\to \infty$ on both sides of (\ref{Proof:thm3:6}) and by
continuity, we get $g^*(\mu_2^*,X_1^*)\ge g^*(\mu_1^*,X_1^*)$. On
the other hand, since $g^*(\mu_2^*,X_1^*)\le \bar
g_n(\mu_2^*,X_1^*)$ and $g^*(\mu_1^*,X_1^*)=\bar
g_n(\mu_1^*,X_1^*)$, we have \[g^*(\mu_2^*,X_1^*)-
g^*(\mu_1^*,X_1^*)\le \bar g_n(\mu_2^*,X_1^*)-\bar
g_n(\mu_1^*,X_1^*)=\bar g_n(\mu_2^*,X_2^*)-\bar
g_n(\mu_1^*,X_1^*)=0.\] Therefore, we obtain that
$g^*(\mu_2^*,X_1^*)=g^*(\mu_1^*,X_1^*)$. Noting that
$\mu_1^*\not=\mu_2^*$ and $g^*(\cdot,X_1^*)$ is strictly concave on
$\mathcal{M}$, we can also find $\varepsilon>0$ such that
\begin{equation}\label{Proof:thm3:7}
g^*\left(\frac{\mu_1^*+\mu_2^*}{2},X_1^*\right)\ge
g^*\left(\mu_2^*,X_1^*\right)+\varepsilon.
\end{equation}
By using the continuity again we have
$g^{k_l+1}(\frac{\mu_1^*+\mu_2^*}{2},X_{k_l})\to
g^*(\frac{\mu_1^*+\mu_2^*}{2},X_1^*)$ and
$g^{k_l+1}(\mu_{k_l+1},X_{k_l})\to g^*(\mu_2^*,X_1^*)$, as $l \to
\infty$. Then by (\ref{Proof:thm3:7}), there exists $l_0$, such that
\begin{equation*}
g^{k_{l_0}+1}\left(\frac{\mu_1^*+\mu_2^*}{2},X_{k_{l_0}}\right)\ge
g^{k_{l_0}+1}\left(\mu_{k_{l_0}+1},X_{k_{l_0}}\right)+\frac{\varepsilon}{2}
\end{equation*}
The above inequality indicates $\mu_{k_{l_0}+1}$ is not the optimal
solution of Problem (\ref{Proof:thm3:1}) (when $k=k_{l_0}+1$). This
is a contradiction!

Therefore, we have $(\mu_1^*,X_1^*)=(\mu_2^*,X_2^*)$, which also
needs to a contradiction. This concludes the proof of the lemma.
\end{proof}

\begin{lemma}\label{sec:3:prop:3}
Let $\left\{(\mu_k,X_k), k=0,1,\cdots\right\}$ be a sequence of
solutions generated by Algorithm SQMP starting from $(\mu_0,X_0)\in
\mathcal{M}\times \mathcal{X}$. If a subsequence
$\left\{(\mu_{k_l},X_{k_l})\right\}$ converges to some point
$(\mu^*,X^*)\in \mathcal{M}\times \mathcal{X}$, then for every fixed
positive integer $s$, the subsequence
$\left\{(\mu_{k_l+s},X_{k_l+s})\right\}$ converges to $(\mu^*,X^*)$.
If $\left\{(\mu_k,X_k), k=0,1,\cdots\right\}$ has a finite number of
cluster points, then $\left\{(\mu_k,X_k), k=0,1,\cdots\right\}$
converges.
\end{lemma}

\begin{proof}
Suppose that subsequence $\left\{(\mu_{k_l},X_{k_l})\right\}$
converges to some point $(\mu^*,X^*)\in \mathcal{M}\times
\mathcal{X}$. By Lemma \ref{sec:3:prop:2} we have the upper limit
\begin{eqnarray*}
\lefteqn{\overline{\lim_{l\to\infty}}~ \|X_{k_l+s}-X_{k_l}\|}\\
&\le& \overline{\lim_{l\to \infty}}~ \left\{\|X_{k_l+1}-X_{k_l}\|
+\|X_{k_l+2}-X_{k_l+1}\|+\cdots+\|X_{k_l+s}-X_{k_l+s-1}\|\right\}\\
&=& \lim_{l\to \infty} \|X_{k_l+1}-X_{k_l}\|+\lim_{l\to \infty}
\|X_{k_l+2}-X_{k_l+1}\|+\cdots+\lim_{l\to \infty} \|X_{k_l+s}-
X_{k_l+s-1}\|\\
&=& 0.
\end{eqnarray*}
Then, it follows from $\lim_{l\to\infty} X_{k_l}=X^*$ that
$\lim_{l\to\infty} X_{k_l+s}=X^*$. Similarly we have
$\lim_{l\to\infty} \mu_{k_l+s}=\mu^*$. Therefore, $\lim_{l\to\infty}
(\|\mu_{k_l+s}-\mu^*\|^2+\|X_{k_l+s}-X^*\|^2)^{1/2}=0$ and
$\left\{(\mu_{k_l+s},X_{k_l+s})\right\}$ converges to $(\mu^*,X^*)$.

If the set of cluster points of $\left\{(\mu_k,X_k),
k=0,1,\cdots\right\}$ is finite, noting Lemma \ref{sec:3:prop:2}, we
have the set is a singleton (Polyak 1987). It follows that
$\left\{(\mu_k,X_k), k=0,1,\cdots\right\}$ converges. We finish the
proof.
\end{proof}

Now we can prove Statement \ref{SQMP:4}.

\begin{proof}
We also prove by contradiction. Suppose there exists a subsequence
$\left\{(\mu_{k_l},X_{k_l})\right\}$ of $\left\{(\mu_k,X_k)
\right\}$, such that $(\mu_{k_l},X_{k_l})\to (\mu^*,X^*)\in
\mathcal{M}\times\mathcal{X}$, and $(\mu^*,X^*)$ is not a stationary
point of Problem (\ref{eqn:saa}).

First suppose there exists a feasible direction $H$ at $X^*$ such
that ${\bf tr}(\nabla_X \bar g_n(\mu^*,X^*)H)>0$. As in the proof of
Lemma \ref{sec:3:prop:2}, we define a new concave conservative
function $f^*(\mu^*,\cdot)$ of $\bar g_n(\mu^*,\cdot)$ on
$\mathcal{X}$:
\begin{equation*}
f^*(\mu^*,X)=\frac{1}{n}\sum_{j=1}^n
\left\{a_js_j^*\left(-\frac{1}{2}(\xi_j-\mu^*)^TX(\xi_j-\mu^*)
+\frac{1}{2}\log\det X\right)+a_j\left(s_j^*-s_j^*\log
s_j^*\right)\right\}
\end{equation*}
where $s_j^*=\exp\left\{-\frac{1}{2}(\xi_j-\mu^*)^TX^*(\xi_j-\mu^*)+
\frac{1}{2}\log\det X^*\right\}, j=1,\cdots,n$. Since $\nabla_X
f^*(\mu^*,X^*)=\nabla_X \bar g_n(\mu^*,X^*)$, we have ${\bf
tr}(\nabla_X f^*(\mu^*,X^*)H)>0$. It follows that we can find
$t_0>0$, such that $X^*+t_0H\in \mathcal{X}$ and
\begin{equation}\label{Proof:thm3:8}
f^*(\mu^*,X^*)<f^*(\mu^*,X^*+t_0H).
\end{equation}
On the other hand, by Algorithm SQMP we have
\begin{equation}\label{Proof:thm3:9}
f^{k_l+1}(\mu_{k_l+1},X_{k_l+1})\ge f^{k_l+1}(\mu_{k_l+1},X^*+t_0H).
\end{equation}
Since $(\mu_{k_l},X_{k_l})\to (\mu^*,X^*)$, by Lemma
\ref{sec:3:prop:3}, we have $(\mu_{k_l+1},X_{k_l+1})\to
(\mu^*,X^*)$. Again, letting $l\to \infty$ on both sides of
(\ref{Proof:thm3:9}) and by continuity we get $f^*(\mu^*,X^*)\ge
f^*(\mu^*,X^*+t_0H)$, which contradicts to (\ref{Proof:thm3:8}).

Now suppose there exists a feasible direction $h$ at $\mu^*$ such
that $\nabla_\mu \bar g_n(\mu^*,X^*)^Th>0$. We define a new concave
conservative function $g^*(\cdot,X^*)$ of $\bar g_n(\cdot,X^*)$ on
$\mathcal{M}$:
\begin{equation*}
g^*(\mu,X^*)=\sum_{j=1}^n
\left\{a_jt_j^*\left(-\frac{1}{2}(\xi_j-\mu)^TX^*(\xi_j-\mu)
+\frac{1}{2}\log\det X^*\right)+a_j\left(t_j^*-t_j^*\log
t_j^*\right)\right\}
\end{equation*}
where $t_j^*=\exp\left\{-\frac{1}{2}(\xi_j-\mu^*)^TX^*(\xi_j-\mu^*)+
\frac{1}{2}\log\det X^*\right\}, j=1,\cdots,n$. Since $\nabla_\mu
g^*(\mu^*,X^*)=\nabla_\mu \bar g_n(\mu^*,X^*)$, we have $\nabla_\mu
g^*(\mu^*,X^*)^Th>0$. It follows that we can find $t_0>0$, such that
$\mu^*+t_0h\in \mathcal{M}$ and
\begin{equation}\label{Proof:thm3:10}
g^*(\mu^*,X^*)<g^*(\mu^*+t_0h,X^*).
\end{equation}
On the other hand, by Algorithm SQMP we have
\begin{equation}\label{Proof:thm3:11}
g^{k_l+1}(\mu_{k_l+1},X_{k_l})\ge g^{k_l+1}(\mu^*+t_0h,X_{k_l}).
\end{equation}
Letting $l\to \infty$ on both sides of (\ref{Proof:thm3:11}) and by
continuity we obtain $g^*(\mu^*,X^*)\ge g^*(\mu^*+t_0h,X^*)$, which
contradicts with (\ref{Proof:thm3:10}).

Therefore, $(\mu^*,X^*)$ must be a stationary point of Problem
(\ref{eqn:saa}). Furthermore, if Problem (\ref{eqn:saa}) has a
finite number of stationary points, then from the above argument we
have that the sequence $\left\{(\mu_k,X_k)\right\}$ also has a
finite number of cluster points. Then by Lemma \ref{sec:3:prop:3},
$\left\{(\mu_k,X_k)\right\}$ converges with its limit being a
stationary point of Problem (\ref{eqn:saa}). This concludes the
proof of Theorem \ref{thm:conv}.
\end{proof}


\section{Proof of Proposition \ref{pro:1}}

\begin{proof}
We only show dominance of the derivative $w.r.t.$ $X$. The proof of
dominance of the gradient $w.r.t.$ $\mu$ is easier and can be done
via similar procedure.

For every $\Sigma\in \mathcal S$, we have
$\Sigma^{-1}\succeq\Sigma_u^{-1}$, i.e., $X-\Sigma_u^{-1}$ is
positive semi-definite for all $X\in \mathcal{X}$. It follows that
for every $X\in \mathcal{X}$, $-\xi^T(X- \Sigma_u^{-1})\xi\le 0$ for
every $\xi\in \Re^d$. Therefore

{\footnotesize{
\begin{eqnarray}
\lefteqn{\left\|\nabla_X
L(\mu,X,\xi)\right\|}\nonumber\\
&=&\left\|(2\pi)^{-d/2}{c(\xi)\over f(\xi)}\exp\left\{-{1\over
2}(\xi-\mu)^T X(\xi-\mu)+{1\over 2}\log\det
X\right\}\left[-\frac{1}{2}(\xi-\mu)(\xi-\mu)^T+\frac{1}{2}X^{-1}
\right]\right\|\nonumber\\
&=& {(2\pi)^{-d/2}c(\xi)\over 2f(\xi)}\exp\left\{-{1\over
2}(\xi-\mu_s)^T
X(\xi-\mu_s)+(\mu-\mu_s)^TX\xi+\frac{1}{2}(\mu_s^TX\mu_s-\mu^TX\mu)+
{1\over 2}\log\det X\right\}\nonumber\\
&&\cdot\left\|-\xi\xi^T+
(\mu\xi^T+\xi\mu^T)-\mu\mu^T+X^{-1}\right\|\nonumber\\
&\le& \frac{A_1c(\xi)}{f(\xi)}\exp\left\{-{1\over2}(\xi-\mu_s)^T
\left(\Sigma_u\right)^{-1}(\xi-\mu_s)+
A_2\left\|\xi\right\|\right\}\left(\left\|
\xi\xi^T\right\|+A_3\left\|\xi\right\|+A_4\right)\nonumber\\
&=& A_5c(\xi)\exp{\left\{A_2\|\xi\|\right\}}\left(\left\|
\xi\xi^T\right\|+A_3\left\|\xi\right\|+A_4\right)\frac{\phi_{(\mu_s,
\Sigma_u)}(\xi)}{f(\xi)}\label{proof:pro:1}
%&\le& A_5
%\left[\frac{1}{1+\gamma}c^{1+\gamma}(\xi)+\frac{\gamma}{1+\gamma}
%\left[\exp{\left\{A_2
%\|\xi\|\right\}}\left(\left\|\xi\xi^T\right\|+A_3\left\|\xi\right\|
%+A_4\right)\right]^{1+\frac{1}{\gamma}}\right]\frac{\phi_{(\mu_s,
%\Sigma_u)}(\xi)}{f(\xi)}
\end{eqnarray}
}}where $A_i, i=1,\cdots, 5$ are some finite constants. Note that we
can easily find the constants $A_i, i=1,\cdots, 5$ because of the
compactness of $\mathcal{M}\times \mathcal{S}$. Now we show the RHS
of (\ref{proof:pro:1}) is integrable under the probability measure
$f(\cdot)$. By changing the measure and using H\"{o}lder's
inequality (Rudin 1976), we have

{\footnotesize{
\begin{eqnarray}
\lefteqn{\E_f\left[A_5c(\xi)\exp{\left\{A_2\|\xi\|\right\}}\left(\left\|
\xi\xi^T\right\|+A_3\left\|\xi\right\|+A_4\right)\frac{\phi_{(\mu_s,
\Sigma_u)}(\xi)}{f(\xi)}\right]}\nonumber\\
&=&
A_{5}\E_{(\mu_s,\Sigma_u)}\left[c(\xi)\exp{\left\{A_2\|\xi\|\right\}}\left(\left\|
\xi\xi^T\right\|+A_3\left\|\xi\right\|+A_4\right)\right]\nonumber\\
&\le& A_{5}\left(\E_{(\mu_s,\Sigma_u)}\left[c^{1+\gamma}
(\xi)\right]\right)^{1/(1+\gamma)}+A_{5}\left(\E_{(\mu_s,\Sigma_u)}\left[\left[\exp{\left\{A_2
\|\xi\|\right\}}\left(\left\|\xi\xi^T\right\|+A_3\left\|\xi\right\|
+A_4\right)\right]^{1+1/\gamma}\right]\right)^{\gamma/(1+\gamma)}\label{proof:pro:21}
\end{eqnarray} }}where $\gamma$ is the constant satisfying
$\E_{(\mu_s,\Sigma_u)}\left[c^{1+\gamma}(\xi)\right]<\infty$. Note
that the second term of the RHS of (\ref{proof:pro:21}) is always
finite valued since $\xi$ follows ${\rm N}(\mu_s,\Sigma_u)$. Then we
have the RHS of (\ref{proof:pro:21}) is finite valued, which shows
Assumption \ref{sec:3:ass:1} holds. The proof is finished.
\end{proof}

%Now we prove the second part. For $\xi\in \Re^d$ and
%$\mu_s\in\Re^d$, denote by $\xi(i)$ and $\mu_s(i)$, $i=1,\ldots,d$
%the $i$th component of $\xi$ and $\mu_s$, respectively. Then for
%every $ X\in \mathcal X_2$, we have
%\begin{equation*}
%{\begin{matrix}
%\begin{bmatrix} \xi-\mu_s \\ -(\xi(i)-\mu_s(i))/\sigma_i^2 \end{bmatrix}
%\end{matrix}}^T\begin{matrix}
%\begin{bmatrix} X & e_i \\ e_i^T & \sigma_i^2 \end{bmatrix}
%\end{matrix}\begin{matrix}
%\begin{bmatrix} \xi-\mu_s \\ -(\xi(i)-\mu_s(i))/\sigma_i^2 \end{bmatrix}
%\end{matrix}\ge 0, i=1,\ldots,d,
%\end{equation*}
%which is equivalent to $-{1\over2}(\xi-\mu_s)^TX(\xi-\mu_s)\le-
%{\left(\xi(i)-\mu_s(i)\right)^2/\left(2\sigma_i^2\right)},
%i=1,\ldots,d$. It follows that
%\begin{equation*}
%-{1\over2}(\xi-\mu_s)^TX(\xi-\mu_s)\le-{1\over2d}\sum_{i=1}^d
%{\left(\xi(i)-\mu_s(i)\right)^2
%\over\sigma_i^2}=-{1\over2}(\xi-\mu_s)^T\left({\rm {\bf
%diag}}\{d\sigma_1^2,\ldots,d\sigma_d^2\}\right)^{-1}(\xi-\mu_s).
%\end{equation*}
%Then, similarly to the proof of the first part, there exist finite
%constants $A_6$, $A_7$, $A_8$ and $A_{9}$, such that

%{\footnotesize{
%\begin{eqnarray}
%\lefteqn{\|\nabla_X
%L(\mu,X,\xi)\|}\nonumber\\
%&=& {(2\pi)^{-d/2}c(\xi)\over 2f(\xi)}\exp\left\{-{1\over
%2}(\xi-\mu_s)^T
%X(\xi-\mu_s)+(\mu-\mu_s)^TX\xi+\frac{1}{2}(\mu_s^TX\mu_s-\mu^TX\mu)+
%{1\over 2}\log\det X\right\}\nonumber\\
%&&\cdot\left\|-\xi\xi^T+
%(\mu\xi^T+\xi\mu^T)-\mu\mu^T+X^{-1}\right\|\nonumber\\
%&\le& \frac{A_6c(\xi)}{f(\xi)}\exp\left\{-{1\over2}(\xi-\mu_s)^T
%\left({\rm{\bf
%diag}}\{d\sigma_1^2,\ldots,d\sigma_d^2\}\right)^{-1}(\xi-\mu_s)+
%A_7\cdot\left\|\xi\right\|\right\}\left(\left\|
%\xi\xi^T\right\|+A_8\cdot\left\|\xi\right\|+A_{9}\right).

%&\le& \left(B_1{(2\pi)^{-d/2}c(\xi)\|(\xi-\mu)(\xi-\mu)^T\|\over
%t(\xi;\mu_s,\Pi,\nu)}+B_2{(2\pi)^{-d/2}c(\xi)\over
%t(\xi;\mu_s,\Pi,\nu)}\right)\exp\left\{-{1\over 2}(\xi-\mu)^T
%X(\xi-\mu)\right\}\nonumber\\
%&\le& B_1{(2\pi)^{-d/2}c(\xi)\|(\xi-\mu)(\xi-\mu)^T\|\over
%t(\xi;\mu_s,\Pi,\nu)}\exp\left\{-{1\over2}(\xi-\mu_s)^T\left({\rm
%{\bf
%diag}}\{d\sigma_1^2,\ldots,d\sigma_d^2\}\right)^{-1}(\xi-\mu_s)
%\right\}\nonumber\\
%&& +B_2{(2\pi)^{-d/2}c(\xi)\over
%t(\xi;\mu_s,\Pi,\nu)}\exp\left\{-{1\over2}(\xi-\mu_s)^T\left({\rm
%{\bf
%diag}}\{d\sigma_1^2,\ldots,d\sigma_d^2\}\right)^{-1}(\xi-\mu_s)\right\}

%\label{appendix:equ:2}
%\end{eqnarray}}}Noting the condition $\E_{(\mu_s,{\rm {\bf
%diag}}\{d\sigma_1^2,\ldots,d\sigma_d^2\})}\left[c^{1+\gamma}(\xi)
%\right]<\infty$, we can similarly prove the RHS of
%(\ref{appendix:equ:2}) is integrable under the probability measure
%$f(\cdot)$.


%\subsection{Proof of Proposition \ref{lem:1}}

%\begin{proof}
%For every $\Sigma\in \mathcal S_1$, we have $-\xi^T(\Sigma^{-1}-
%\Sigma_u^{-1})\xi\le 0$ for every $\xi\in \Re^d$. Plugging the
%function form of the underlying density, we obtain
%\begin{eqnarray}
%\lefteqn{
%\E_{(\mu_s,\Sigma_u)}\left[\left(c(\xi){\phi_{(\mu,\Sigma)}
%(\xi)\over \phi_{(\mu_s,\Sigma_u)}(\xi)}\right)^2\right]}\nonumber\\
%&=&\frac{\det\Sigma_u}{\det\Sigma}
%\cdot\frac{\exp{\left\{\mu_s^T\Sigma_u^{-1}\mu_s\right\}}}
%{\exp{\left\{\mu^T\Sigma^{-1}\mu\right\}}}\cdot\E_{(\mu_s,\Sigma_u)}
%\left[c^2(\xi)\exp{\left\{-\xi^T(\Sigma^{-1}-\Sigma_u^{-1})\xi+2\left
%(\mu^T\Sigma^{-1}-\mu_s^T\Sigma_u^{-1}\right)\xi\right\}}
%\right]\nonumber\\
%&\le&A_{10}\cdot\E_{(\mu_s,\Sigma_u)}\left[c^2(\xi)\exp{\left\{2
%\left(\mu^T\Sigma^{-1}-\mu_s^T
%\Sigma_u^{-1}\right)\xi\right\}}\right]\label{proof:lem1}.
%\end{eqnarray}
%where \[A_{10}=\sup_{(\mu,\Sigma)\in\mathcal{M}\times
%\mathcal{S}_1}~ \frac{\det\Sigma_u}{\det\Sigma}
%\cdot\frac{\exp{\left\{\mu_s^T\Sigma_u^{-1}\mu_s\right\}}}{\exp{\left\{
%\mu^T\Sigma^{-1}\mu\right\}}}<\infty.\] We only need to prove the
%right hand side (RHS) of (\ref{proof:lem1}) is bounded on $\mathcal
%M\times \mathcal S_1$. By Young's inequality again,
%\begin{eqnarray}
%\lefteqn{ c^2(\xi)\exp{\left\{2\left(\mu^T\Sigma^{-1}-\mu_s^T
%\Sigma_u^{-1}\right)\xi\right\}}}\nonumber\\
%&\le&
%\frac{1}{1+\gamma/2}\left[c^2(\xi)\right]^{1+\gamma/2}+\frac{1}
%{1+2/\gamma}\left[\exp{\left\{2\left(\mu^T\Sigma^{-1}-\mu_s^T
%\Sigma_u^{-1}\right)\xi\right\}}\right]
%^{1+2/\gamma}\nonumber\\
%&=&\frac{1}{1+\gamma/2}c^{2+\gamma}(\xi)+\frac{1}{1+2/\gamma}
%{\exp{\left\{(2+4/\gamma)\left(\mu^T\Sigma^{-1}-\mu_s^T
%\Sigma_u^{-1}\right)\xi\right\}}}.\label{proof:lem11}
%\end{eqnarray}
%Now it suffices to prove the expectation of the RHS of
%(\ref{proof:lem11}) is bounded. Note that the moment generating
%function of a MVN distribution is finite valued and continuous. It
%follows that the expectation
%$\E_{(\mu_s,\Sigma_u)}\left[\exp{\left\{(1+2/\gamma)\left(\mu^T
%\Sigma^{-1}-\mu_s^T\Sigma_u^{-1}\right)\xi\right\}}\right]$, as a
%function of $(\mu,\Sigma)$, is finite valued and continuous on
%$\mathcal M\times \mathcal S_1$, and therefore bounded on $\mathcal
%M\times \mathcal S_1$. Moreover, by the conditions of the lemma, we
%have $\E_{(\mu_s,\Sigma_u)}\left[c^{2+\gamma}(\xi)\right]<\infty$.
%Then, the expectation of the RHS of (\ref{proof:lem11}) is bounded.
%This concludes the proof of the proposition.
%\end{proof}

%\subsection{Proof of Proposition \ref{lem:t}}

%\begin{proof}
%Similarly to Proposition \ref{lem:1}, it suffices to show that for
%any vector $\mu_s\in\Re^d$, any positive definite $d\times d$ matrix
%$\Pi$ and any positive integer $\nu$, the second moment

%{\small{
%\begin{eqnarray*}
%\lefteqn{ \E_{t}\left[\left(c(\xi){\phi_{(\mu,\Sigma)}(\xi)\over
%t(\xi;\mu_s,\Pi,\nu)}\right)^2\right] }\\
%&=& \int_{\Re^d} {c^2(x)\over
%t(x;\mu_s,\Pi,\nu)}(2\pi)^{-d}\left(\det\Sigma\right)^{-1}\exp{\left
%\{-{1\over 2}(x-\mu)^T(2\Sigma^{-1})(x-\mu)\right\}}dx\\
%&=& \int_{\Re^d}{c^2(x)(2\pi)^{-d/2}(\det{1\over2}\Sigma)^{1/2}\over
%t(x;\mu_s,\Pi,\nu)\det\Sigma}(2\pi)^{-d/2}(\det{1\over2}\Sigma)^{-1/2}
%\exp{\left\{-{1\over 2}(x-\mu)^T({1\over2}\Sigma)^{-1}(x-\mu)\right\}}dx\\
%&=&\E_{(\mu,{1\over2}\Sigma)}\left[{c^2(\xi)(2\pi)^{-d/2}
%(\det{1\over2}\Sigma)^{1/2}\over t(\xi;\mu_s,\Pi,\nu)\det\Sigma}\right]\\
%&=&{\nu^{d/2}\Gamma(\nu/2)\over
%2^d\Gamma((\nu+d)/2)}{(\det\Pi)^{1/2}\over(\det\Sigma)^{1/2}}\cdot
%\E_{(\mu,{1\over2}\Sigma)}
%\left[c^2(\xi)\left(1+{(\xi-\mu_s)^T\Pi^{-1}(\xi-\mu_s)\over\nu}\right)
%^{(\nu+d)/2}\right]
%\end{eqnarray*}}}is bounded on $\mathcal M\times\mathcal S_2$. Since
%$\mathcal S_2$ is compact in $\mathbb{S}_{++}^d$, we have
%$(\det\Pi)^{1/2}/(\det\Sigma)^{1/2}$ is bounded on $\mathcal S_2$.
%Moreover, we have $\sup_{(\mu,\Sigma)\in \mathcal M\times\mathcal
%S_2} \E_{(\mu,{1\over2}\Sigma)}
%\left[c^{2+\gamma}(\xi)\right]<\infty$ by the conditions in the
%lemma, and the expectation
%$\E_{(\mu,{1\over2}\Sigma)}\left[{\left(1+{(\xi-\mu_s)^T\Pi^{-1}
%(\xi-\mu_s)\over\nu}\right)^{(\nu+d)\left({1/2+1/\gamma}\right)}}\right]$,
%as a function of $(\mu,\Sigma)$, is finite valued and continuous on
%$\mathcal M\times \mathcal S_2$. Then, the proof can be finished by
%applying the same procedure in Proposition \ref{lem:1}.
%\end{proof}


\section{Proof of Theorem \ref{sec:3:thm:1}}

We first prove the following lemma.

\begin{lemma}\label{sec:3:lem:1}
Suppose that Assumption \ref{sec:3:ass:1} is satisfied. Then,
$L(\mu,X,\xi)$ is Lipschitz continuous, i.e., for all
$(\mu_i,X_i)\in \mathcal{M}\times\mathcal {X},i=1,2,$ and all
$\xi\in \Re^d$,
\begin{equation*}
|L(\mu_1,X_1,\xi)-L(\mu_2,X_2,\xi)|\le
D_1(\xi)\|\mu_1-\mu_2\|+D_2(\xi)\|X_1-X_2\|.
\end{equation*}
\end{lemma}

\begin{proof}
For any $(\mu_i,X_i)\in \mathcal{M}\times\mathcal {X},i=1,2$ and
$\xi\in \Re^d$, construct a function
\[l(t)=L(\mu_2+t(\mu_1-\mu_2),X_2+t(X_1-X_2),\xi)\] on interval
$[0,1]$, then $l(t)$ is continuously differentiable and
\begin{eqnarray*}
l'(t) &=& \nabla_{\mu}L(\mu_2+t(\mu_1-\mu_2),X_2+t(X_1-X_2),\xi)^T
(\mu_1-\mu_2)\\
&&\ +{\bf tr}\left(\nabla_{X}L(\mu_2+t(\mu_1-\mu_2),X_2+t(X_1-X_2),
\xi)(X_1-X_2)\right).
\end{eqnarray*}
By the mean value theorem (Rudin 1976), there exists $\bar t\in
[0,1]$, such that $|l(1)-l(0)|=l'(\bar t)$. Let $(\bar\mu,\bar
X)=(\mu_2+\bar t(\mu_1-\mu_2),X_2+\bar t(X_1-X_2))$, then it follows
that
\begin{eqnarray}
\left|L(\mu_1,X_1,\xi)-L(\mu_2,X_2,\xi)\right|&=&\left|\nabla_{\mu}
L(\bar\mu,\bar X,\xi)^T (\mu_1-\mu_2)+{\bf
tr}\left(\nabla_{X}L(\bar\mu,\bar X,
\xi)(X_1-X_2)\right)\right|\nonumber\\
&\le& \left\|\nabla_{\mu}L(\bar\mu,\bar
X,\xi)\right\|\left\|\mu_1-\mu_2\right\|+\left\|\nabla_{X}L(\bar\mu,\bar
X,\xi)\right\|\left\|X_1-X_2\right\|\nonumber\\
&\le&
D_1(\xi)\left\|\mu_1-\mu_2\right\|+D_2(\xi)\left\|X_1-X_2\right\|.\nonumber
\end{eqnarray}
This concludes the proof of the lemma.
\end{proof}

Now we can prove Theorem \ref{sec:3:thm:1}.
\begin{proof}
First, we fix a point $(\mu_1,X_1)\in\mathcal{M}\times\mathcal {X}$.
By change of measure we have
$\E_f\left[|L(\mu_1,X_1,\xi)|\right]=\E_{(\mu_1,X_1^{-1})}
\left[c(\xi)\right]<\infty$. Second, for every
$(\mu,X)\in\mathcal{M}\times\mathcal {X}$ and $\xi\in \Re^d$, by
Lemma \ref{sec:3:lem:1} we have
\[
|L(\mu,X,\xi)|\le |L(\mu_1,X_1,\xi)|+
D_1(\xi)\|\mu-\mu_1\|+D_2(\xi)\|X-X_1\|\le |L(\mu_1,X_1,\xi)|+
\kappa_1D_1(\xi)+\kappa_2D_2(\xi),
\]
where $\kappa_1=\sup_{\mu',\mu''\in
\mathcal{M}}\|\mu'-\mu''\|<\infty$ and $\kappa_2=\sup_{X',X''\in
\mathcal{X}}\|X'-X''\|<\infty$. This shows that $L(\mu,X,\xi)$ is
dominated by an integrable function. Note that $L(\mu,X,\xi)$ is
continuous on $\mathcal{M}\times\mathcal {X}$ for every $\xi\in
\Re^d$. By using Theorem 7.48 of Shapiro et al. (2009) and its
corresponding proof (only need to replace the Euclidean space with
$\Re^d\times \mathbb S^d$), we have $g(\mu,X)$ is continuous on
$\mathcal{M}\times\mathcal {X}$ and $\bar g_n(\mu,X)$ converges to
$g(\mu,X)$ $w.p.1$ uniformly on $\mathcal{M}\times\mathcal {X}$.
Then the nonemptiness of $S$ and $\bar S_n$ follows from the
continuity of $g(\mu,X)$ and $\bar g_n(\mu,X)$. Finally, by Theorem
5.3 of Shapiro et al. (2009) and the corresponding proof (only need
to replace the Euclidean space with $\Re^d\times \mathbb S^d$), we
have $\bar v_n\to v$ and $\mathbb{D}(\bar S_n,S)\to 0$ $w.p.1$ as
$n\to \infty$.
\end{proof}


\section{Proof of Theorem \ref{sec:3:thm:2}}

To prove Theorem \ref{sec:3:thm:2} we need the following lemma.

\begin{lemma}\label{sec:3:lem:2}
Suppose that Assumption \ref{sec:3:ass:1} is satisfied.  Then,
$g(\cdot)$ is continuously differentiable on
$\mathcal{M}\times\mathcal{X}$, $\nabla_{\mu}
g(\mu,X)=\E_f\left[\nabla_{\mu} L(\mu,X,\xi)\right]$, $\nabla_X
g(\mu,X)=\E_f\left[\nabla_X L(\mu,X,\xi)\right]$ and, $w.p.1$,
\begin{equation*}
\sup_{(\mu,X)\in\mathcal{M}\times\mathcal {X}}\|\bar
\psi_{\mu,n}(\mu,X)-\nabla_{\mu} g(\mu,X)\|\to 0, \quad
\sup_{(\mu,X)\in\mathcal{M}\times\mathcal {X}}\|\bar
\psi_{X,n}(\mu,X)-\nabla_X g(\mu,X)\|\to 0
\end{equation*}
as $n\to\infty$, where
$\bar\psi_{\mu,n}(\mu,X)=\frac{1}{n}\sum_{j=1}^n\nabla_{\mu}
L(\mu,X,\xi_j)$ and
$\bar\psi_{X,n}(\mu,X)=\frac{1}{n}\sum_{j=1}^n\nabla_X
L(\mu,X,\xi_j)$.
\end{lemma}

\begin{proof}
By Jensen's inequality (Durrett 2005) and Lemma \ref{sec:3:lem:1},
we have for any $(\mu_i,X_i)\in \mathcal{M}\times\mathcal
{X},i=1,2$,
\begin{eqnarray*}
|g(\mu_1,X_1)-g(\mu_2,X_2)|&\le&
\E_f\left[|L(\mu_1,X_1,\xi)-L(\mu_2,X_2,\xi)|\right]\\
&\le&
\E_f\left[D_1(\xi)\right]\cdot\|\mu_1-\mu_2\|+\E_f\left[D_2(\xi)\right]
\cdot\|X_1-X_2\|.
\end{eqnarray*}
This further indicates that the objective function $g(\cdot)$ is
Lipschitz continuous. Moreover, for any $X\in \mathcal{X}$ and $H\in
\mathbb S^d$, we can apply the Lebesgue dominated convergence
theorem (Durrett 2005) to calculate the directional derivative
\begin{eqnarray*}
g'(\mu,X,H)&:=&\lim_{t\searrow
0}\frac{1}{t}\left\{g(\mu,X+tH)-g(\mu,X)\right\}\ = \
\lim_{t\searrow
0}\E_f\left[\frac{1}{t}\left\{L(\mu,X+tH,\xi)-L(\mu,X,\xi)\right\}
\right]\\
&=& \E_f\left[\lim_{t\searrow
0}\frac{1}{t}\left\{L(\mu,X+tH,\xi)-L(\mu,X,\xi)\right\}\right]\ = \
\E_f\left[{\bf tr}\left(\nabla_X L(\mu,X,\xi)\ H\right)\right]\\
& =& {\bf tr}\left(\E_f\left[\nabla_X L(\mu,X,\xi)\right]\ H\right).
\end{eqnarray*}
We obtain that the directional derivative $g'(\mu,X,H)$ is linear in
$H$. Therefore, by Theorem 7.2 of Shapiro et al. (2009) and its
proof, we have that $g(\mu,X)$ is differentiable $w.r.t.$ $X$ (in
the sense of Fr\'{e}chet) and $\nabla_X g(\mu,X)=\E_f\left[\nabla_X
L(\mu,X,\xi)\right]$. Consider now a sequence
$\{(\mu_n,X_n)\}\subset \mathcal{M}\times\mathcal {X}$ converging to
a point $(\mu^*,X^*)\in \mathcal{M}\times\mathcal {X}$. By applying
the Lebesgue dominated convergence theorem again, we have
\begin{eqnarray*}
\lim_{n\to \infty}\nabla_X g(\mu_n,X_n)&=&\lim_{n\to
\infty}\E_f\left[\nabla_X
L(\mu_n,X_n,\xi)\right]=\E_f\left[\lim_{n\to \infty}\nabla_X
L(\mu_n,X_n,\xi)\right]\\
&=&\E_f\left[\nabla_X L(\mu^*,X^*,\xi)\right]=\nabla_X g(\mu^*,X^*).
\end{eqnarray*}
This means $\nabla_X g(\mu,X)$ is continuous on
$\mathcal{M}\times\mathcal {X}$. Applying the same procedure we can
prove that $\nabla_{\mu} g(\mu,X)=\E_f\left[\nabla_{\mu}
L(\mu,X,\xi)\right]$ and is continuous on $\mathcal{M}\times\mathcal
{X}$. Finally, by Theorem 7.48 of Shapiro et al. (2009) (only need
to replace $\Re^n$, $X$ and the absolute value $|\cdot|$ therein
with $\Re^d\times\mathbb{S}^d$, $\mathcal{M}\times\mathcal{X}$ and
$\|\cdot\|$, respectively), we have $\bar \psi_{\mu,n}(\cdot)$
converges to $\nabla_{\mu} g(\cdot)$ and $\bar \psi_{X,n}(\cdot)$
converges to $\nabla_X g(\cdot)$ $~w.p.1$ uniformly on
$\mathcal{M}\times\mathcal {X}$. This completes the proof.
\end{proof}

Now we can prove Theorem \ref{sec:3:thm:2}. The proof below is a
slight revision of the proof of Theorem 5.12 of Shapiro et al.
(2009).

\begin{proof}
The nonemptiness of $\bar K_n$ and $K$ follows from the fact that
$\bar K_n\supseteq \bar S_n$ and $K\supseteq S_n$. To prove the
almost sure convergence of $\bar K_n$ to $K$, we can view
$\bar\psi_{\mu,n}(\mu,X)=\bar\psi_{\mu,n}(\mu,X,\omega)$ and
$\bar\psi_{X,n}(\mu,X)=\bar\psi_{X,n}(\mu,X,\omega)$ as defined on a
common probability space
\begin{equation*}
\Xi^{\infty}=\left\{(\xi_1,\xi_2,\cdots):\xi_j\in \Re^d,
j=1,2,\cdots\right\}.
\end{equation*}
Define the set
\begin{equation*}
\Omega=\left\{\omega\in \Xi^{\infty}:\begin{array}{ll}
\sup_{(\mu,X)\in\mathcal{M}\times\mathcal {X}}\|\bar
\psi_{\mu,n}(\mu,X,\omega)-\nabla_\mu g(\mu,X)\|\to 0\\
\sup_{(\mu,X)\in\mathcal{M}\times\mathcal {X}}\|\bar
\psi_{X,n}(\mu,X,\omega)-\nabla_X g(\mu,X)\|\to 0
\end{array}
\right\}.
\end{equation*}
Suppose Assumption \ref{sec:3:ass:1} is satisfied. Then by Lemma
\ref{sec:3:lem:2}, we have $\Pr(\Omega)=1$. Now we only need to
prove $\mathbb{D}(\bar K_n,K)\to 0$ for every $\omega\in \Omega$.
Once $\omega$ is given, everything becomes deterministic and hence
we can omit the term $\omega$ and view the underlying problem as a
deterministic problem. Consider a sequence $(\mu_n,X_n)\in \bar
K_n$, by passing to a subsequence if necessary, we only need to show
that if $(\mu_n,X_n)\in \bar K_n$ converges to a point
$(\mu^*,X^*)$, then $(\mu^*,X^*)\in \bar K$. Applying the triangular
inequality, we get
\begin{equation*}
\|\bar \psi_{X,n}(\mu_n,X_n)-\nabla_X g(\mu^*,X^*)\|\le\|\bar
\psi_{X,n}(\mu_n,X_n)-\nabla_X g(\mu_n,X_n)\|+ \|\nabla_X
g(\mu_n,X_n)-\nabla_X g(\mu^*,X^*)\|.
\end{equation*}
Noting that $|\bar \psi_{X,n}(\mu_n,X_n)-\nabla_X g(\mu_n,X_n)\|\to
0$ because of uniform convergence of $\bar \psi_{X,n}(\cdot)$ to
$\nabla_X g(\cdot)$, and that $\|\nabla_X g(\mu_n,X_n)-\nabla_X
g(\mu^*,X^*)\|\to 0$ because of the continuity of $\nabla_X
g(\cdot)$, we obtain that $\bar \psi_{X,n}(\mu_n,X_n)\to \nabla_X
g(\mu^*,X^*)$. Since $\bar \psi_{X,n}(\mu_n,X_n)\in
N_{\mathcal{X}}(X_n)$, it follows from Proposition 6.6 (limits of
normal vectors) of Rockafellar and Wets (1998) that $\nabla_X
g(\mu^*,X^*)\in N_{\mathcal{X}}(X^*)$. Similarly, we can prove
$\nabla_\mu g(\mu^*,X^*)\in N_{\mathcal{M}}(\mu^*)$. Therefore, we
have $(\mu^*,X^*)\in \bar K$. This concludes the proof of the
theorem.
\end{proof}
